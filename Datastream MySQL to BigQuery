#Datastream MySQL to BigQuery

BASIC COMMANDS

gcloud auth lsit

gcloud config list project

PROJECT_ID=<Replace with your Project ID>


<!--STEP-1--> Create a Cloud SQL database instance

MYSQL_INSTANCE=mysql-db
DATASTREAM_IPS=34.72.28.29,34.67.234.134,34.67.6.157,34.72.239.218,34.71.242.81
gcloud sql instances create ${MYSQL_INSTANCE} \
    --cpu=2 --memory=10GB \
    --authorized-networks=${DATASTREAM_IPS} \
    --enable-bin-log \
    --region=us-central1 \
    --database-version=MYSQL_8_0 \
    --root-password password123
    
<!--step-2>    
    
gsutil mb gs://${PROJECT_ID}


gcloud pubsub topics create datastream
gcloud pubsub subscriptions create datastream-subscription --topic=datastream
gsutil notification create -f "json" -p "data/" -t "datastream" "gs://${PROJECT_ID}"


<!--STEP-3-->

nano create_mysql.sql

#paste the below code -->

CREATE DATABASE IF NOT EXISTS test;
USE test;
CREATE TABLE IF NOT EXISTS test.example_table (
id INT NOT NULL AUTO_INCREMENT PRIMARY KEY,
text_col VARCHAR(50),
int_col INT,
created_at TIMESTAMP
);
INSERT INTO test.example_table (text_col, int_col, created_at) VALUES
('hello', 0, '2020-01-01 00:00:00'),
('goodbye', 1, NULL),
('name', -987, NOW()),
('other', 2786, '2021-01-01 00:00:00');


SERVICE_ACCOUNT=$(gcloud sql instances describe ${MYSQL_INSTANCE} | grep serviceAccountEmailAddress | awk '{print $2;}')
gsutil cp create_mysql.sql gs://${PROJECT_ID}/resources/create_mysql.sql
gsutil iam ch serviceAccount:${SERVICE_ACCOUNT}:objectViewer gs://${PROJECT_ID}
gcloud sql import sql ${MYSQL_INSTANCE} gs://${PROJECT_ID}/resources/create_mysql.sql --quiet




<!--STEP-4-->  Create Datastream resources

#ENABLE THE DATASTREAM SECTION

#Create Connection Profiles

#FOLLOW NEXT STEPS FROM VIDEO
